#!/usr/bin/env python3
"""
AI Basketball / Soccer Analysis Dashboard â€” ç”¨æˆ·è¡Œä¸ºä¸æ•°æ®è¡¨ç°ï¼ˆå®šæ€§+å®šé‡åˆ†æï¼‰
Data source: data/processed/*.csv (from PDF extraction or mock).
Run: streamlit run app.py
"""
from pathlib import Path

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

PROJECT_ROOT = Path(__file__).resolve().parent
PROCESSED_DIR = PROJECT_ROOT / "data" / "processed"


@st.cache_data
def load_data():
    kpi = pd.read_csv(PROCESSED_DIR / "kpi.csv", encoding="utf-8")
    peak_7d = pd.read_csv(PROCESSED_DIR / "peak_7d.csv", encoding="utf-8")
    peak_48h = pd.read_csv(PROCESSED_DIR / "peak_48h.csv", encoding="utf-8")
    daily_usage = pd.read_csv(PROCESSED_DIR / "daily_usage.csv", encoding="utf-8")
    new_users = pd.read_csv(PROCESSED_DIR / "new_users.csv", encoding="utf-8")
    return kpi, peak_7d, peak_48h, daily_usage, new_users


def build_narrative(kpi_sel, peak_7d_sel, peak_48h_sel, daily_usage_sel, new_users_sel, selected_products):
    """åŸºäºå½“å‰ç­›é€‰æ•°æ®ç”Ÿæˆå™äº‹æ€§è§£è¯»ä¸å»ºè®®ã€‚"""
    total_users = int(kpi_sel["value"].sum())
    observation_period = ""
    all_dates = []
    for df in [peak_7d_sel, daily_usage_sel, new_users_sel]:
        if not df.empty and "date" in df.columns:
            all_dates.extend(df["date"].astype(str).tolist())
    if all_dates:
        observation_period = f"{min(all_dates)} è‡³ {max(all_dates)}"
    if total_users <= 0:
        return {"summary": "å½“å‰ç­›é€‰ä¸‹æš‚æ— ç”¨æˆ·é‡æ•°æ®ã€‚", "findings": [], "suggestions": ["è¯·æ£€æŸ¥æ•°æ®æˆ–è°ƒæ•´äº§å“çº¿ç­›é€‰ã€‚"], "observation_period": observation_period}

    # ----- ç»Ÿä¸€è®¡ç®—å…³é”®æŒ‡æ ‡ï¼ˆä¾› findings ä¸ suggestions å…±ç”¨ï¼‰-----
    lead_product, lead_count, lead_pct = None, None, None
    if len(selected_products) >= 2:
        a = kpi_sel[kpi_sel["product_line"] == selected_products[0]]["value"].sum()
        b = kpi_sel[kpi_sel["product_line"] == selected_products[1]]["value"].sum()
        if a + b > 0:
            lead_product = selected_products[0] if a >= b else selected_products[1]
            lead_count = int(a if lead_product == selected_products[0] else b)
            lead_pct = round(100 * lead_count / total_users, 1)

    dau_mean, max_dau, max_dau_date = None, None, None
    if not daily_usage_sel.empty:
        dau_mean = float(daily_usage_sel.groupby("date")["dau"].sum().mean())
        max_dau = int(daily_usage_sel["dau"].max())
        max_dau_date = daily_usage_sel.loc[daily_usage_sel["dau"].idxmax(), "date"]

    total_new, zero_days, new_peak = None, None, None
    if not new_users_sel.empty:
        new_by_date = new_users_sel.groupby("date")["new_ai_users"].sum()
        total_new = int(new_by_date.sum())
        zero_days = int((new_by_date == 0).sum())
        new_peak = int(new_users_sel["new_ai_users"].max())

    peak_date, peak_val = None, None
    if not peak_7d_sel.empty:
        agg7 = peak_7d_sel.groupby("date", as_index=False)["task_cnt"].sum()
        if not agg7.empty:
            peak_date = agg7.loc[agg7["task_cnt"].idxmax(), "date"]
            peak_val = int(agg7["task_cnt"].max())

    busy_slot = None
    if not peak_48h_sel.empty and peak_48h_sel["task_cnt"].sum() > 0:
        agg48 = peak_48h_sel.groupby("hour_slot")["task_cnt"].sum()
        busy_slot = agg48.idxmax()

    # ----- æ‘˜è¦ï¼ˆä¿æŒä¸å˜ï¼‰-----
    product_breakdown = []
    for p in selected_products:
        v = kpi_sel[kpi_sel["product_line"] == p]["value"].sum()
        if v > 0:
            pct = round(100 * v / total_users, 1)
            product_breakdown.append(f"{p} {int(v)} äººï¼ˆ{pct}%ï¼‰")
    summary_parts = [f"æœ¬å‘¨æœŸå†…ï¼Œæ‰€é€‰äº§å“çº¿**ç´¯è®¡ç”¨æˆ·å…± {total_users} äºº**"]
    if product_breakdown:
        summary_parts.append("ï¼Œå…¶ä¸­ " + "ã€".join(product_breakdown) + "ã€‚")
    else:
        summary_parts.append("ã€‚")
    if peak_date is not None:
        summary_parts.append(f"**è¿‘7å¤©åŠŸèƒ½ä½¿ç”¨é«˜å³°**å‡ºç°åœ¨ {peak_date}ï¼ˆå½“æ—¥ä»»åŠ¡é‡ {peak_val}ï¼‰ã€‚")
    if max_dau is not None:
        summary_parts.append(f"**æ—¥æ´»å³°å€¼**ä¸º {max_dau} äººï¼ˆ{max_dau_date}ï¼‰ã€‚")
    if total_new is not None:
        summary_parts.append(f"è§‚æµ‹æœŸå†…**æ–°å¢ç”¨æˆ·åˆè®¡ {total_new} äºº**ï¼Œå•æ—¥æ–°å¢æœ€é«˜ {new_peak} äººã€‚")
    summary = " ".join(summary_parts)

    # ----- ä¸»è¦å‘ç°ï¼šç»“è®º + æ•°æ® + ä¸šåŠ¡å«ä¹‰ -----
    findings = []
    if lead_product is not None:
        findings.append(
            f"**äº§å“çº¿å¯¹æ¯”**ï¼š{lead_product} é¢†å…ˆï¼ˆå…± {lead_count} äººï¼Œå  {lead_pct}%ï¼‰ï¼Œæ˜¯å½“å‰ä¸»è¦ç”¨æˆ·æ¥æºï¼Œèµ„æºå€¾æ–œæœ‰æ•°æ®æ”¯æ’‘ï¼›å¯è€ƒè™‘ä»è¯¥çº¿å‘å¦ä¸€æ¡çº¿å¯¼æµæ‹‰æ–°ã€‚"
        )
    if dau_mean is not None:
        peak_part = f"ï¼Œå³°å€¼ {max_dau} äººï¼ˆ{max_dau_date}ï¼‰" if max_dau is not None else ""
        findings.append(
            f"**æ´»è·ƒåº¦**ï¼šè§‚æµ‹æœŸå†…æ—¥å‡æ´»è·ƒçº¦ {dau_mean:.1f} äºº{peak_part}ï¼›æ•´ä½“è§„æ¨¡ä»å°ã€æ³¢åŠ¨æ˜æ˜¾ï¼Œç•™å­˜ä¸ä¹ æƒ¯å°šæœªç¨³å®šï¼Œéœ€é€šè¿‡æ´»åŠ¨ä¸è§¦è¾¾æå‡ã€‚"
        )
    if zero_days is not None and zero_days > 0:
        findings.append(
            f"**æ–°å¢èŠ‚å¥**ï¼šè§‚æµ‹æœŸå†…å…± {zero_days} å¤©é›¶æ–°å¢ã€ç´¯è®¡æ–°å¢ {total_new} äººï¼›æ‹‰æ–°ä¸ç¨³å®šï¼Œéœ€æ’æŸ¥æ›å…‰ä¸è½¬åŒ–æ¼æ–—ã€‚"
        )
    if busy_slot is not None:
        findings.append(
            f"**48 å°æ—¶é«˜å³°**ï¼šä½¿ç”¨é›†ä¸­åœ¨ã€Œ{busy_slot}ã€æ—¶æ®µï¼›å»ºè®®åœ¨è¯¥æ—¶æ®µä¿éšœæœåŠ¡å®¹é‡ä¸ç¨³å®šæ€§ï¼Œå¹¶å¯åšè½»é‡æ¨é€ä»¥æå‡è½¬åŒ–ã€‚"
        )

    # ----- å»ºè®®ä¸‹ä¸€æ­¥ï¼šç”±æ•°æ®ä¸å‘ç°åŠ¨æ€ç”Ÿæˆï¼ˆä¾æ® + å…·ä½“åŠ¨ä½œï¼‰-----
    suggestions = []
    if zero_days is not None and zero_days > 0:
        suggestions.append(
            f"**æ‹‰æ–°**ï¼šåŸºäºè§‚æµ‹æœŸå†… {zero_days} å¤©é›¶æ–°å¢ã€ç´¯è®¡ {total_new} äººæ–°å¢ï¼Œå»ºè®®æœ¬å‘¨å†…å®Œæˆå„æ¸ é“æ›å…‰ä¸è½¬åŒ–æ¼æ–—æ‹†è§£ï¼Œå¹¶è®¾å®šä¸‹æœˆæ‹‰æ–°ç›®æ ‡ã€è½å®åˆ°æ¸ é“è´Ÿè´£äººã€‚"
        )
    if busy_slot is not None:
        suggestions.append(
            f"**èµ„æºä¸èŠ‚å¥**ï¼šä½¿ç”¨é›†ä¸­åœ¨ã€Œ{busy_slot}ã€ï¼Œå»ºè®®åœ¨è¯¥æ—¶æ®µä¿è¯æœåŠ¡å®¹é‡å¹¶å®‰æ’è½»é‡æ¨é€ï¼Œä»¥æå‡è½¬åŒ–ã€‚"
        )
    if lead_product is not None:
        other = [p for p in selected_products if p != lead_product]
        other_line = other[0] if other else "å¦ä¸€æ¡çº¿"
        suggestions.append(
            f"**äº§å“çº¿**ï¼š{lead_product} å½“å‰é¢†å…ˆï¼ˆ{lead_count} äººï¼Œ{lead_pct}%ï¼‰ï¼Œå»ºè®®ä¼˜å…ˆä¿éšœè¯¥çº¿èµ„æºä¸ä½“éªŒï¼Œå¹¶è®¾è®¡å‘{other_line}çš„å¯¼æµå®éªŒï¼ˆå…¥å£ã€æ´»åŠ¨æˆ–æ–‡æ¡ˆï¼‰ã€‚"
        )
    if dau_mean is not None:
        suggestions.append(
            f"**æ´»è·ƒä¸ç•™å­˜**ï¼šæ—¥å‡æ´»è·ƒçº¦ {dau_mean:.1f} äººï¼Œå»ºè®®è®¾å®šç•™å­˜ä¸å”¤é†’èŠ‚å¥ï¼ˆå¦‚æ¯å‘¨ä¸€æ¬¡è§¦è¾¾ï¼‰ï¼Œå¹¶è·Ÿè¸ªæ¬¡å‘¨ç•™å­˜ä»¥è¯„ä¼°æ´»åŠ¨æ•ˆæœã€‚"
        )
    if peak_date is not None:
        suggestions.append(
            f"**è¿‘ 7 å¤©èŠ‚å¥**ï¼šé«˜å³°æ—¥åœ¨ {peak_date}ï¼ˆä»»åŠ¡é‡ {peak_val}ï¼‰ï¼Œå»ºè®®å°†åŠŸèƒ½ä¸è¿è¥èµ„æºå‘è¯¥æ—¥å‰åé›†ä¸­ï¼Œä½å³°æ—¥åšå®šå‘å¬å›ï¼ˆæ¨é€ã€æ´»åŠ¨ï¼‰ã€‚"
        )
    if not suggestions:
        suggestions.append("å½“å‰æ•°æ®ä¸‹æš‚æ— å¼ºæ•°æ®æ”¯æ’‘çš„ä¸“é¡¹å»ºè®®ï¼Œå¯ç»“åˆä¸Šæ–¹å›¾è¡¨åšäººå·¥è§£è¯»å¹¶è®¾å®šä¸‹æœŸå¤ç›˜æŒ‡æ ‡ã€‚")

    return {"summary": summary, "findings": findings, "suggestions": suggestions, "observation_period": observation_period}


def main():
    st.set_page_config(page_title="AI åˆ†æçœ‹æ¿", layout="wide")
    st.title("AI ç¯®çƒ / è¶³çƒåˆ†æçœ‹æ¿")
    st.caption("ç”¨æˆ·è¡Œä¸ºä¸æ•°æ®è¡¨ç° â€” å®šæ€§å®šé‡åˆ†æ")
    st.markdown("æœ¬æŠ¥å‘Šä»**ç”¨æˆ·è§„æ¨¡ã€ä½¿ç”¨èŠ‚å¥ã€æ´»è·ƒä¸å¢é•¿**ä¸‰ä¸ªç»´åº¦å‘ˆç°æ•°æ®ï¼Œå¹¶åœ¨æ–‡æœ«ç»™å‡ºè§£è¯»ä¸å»ºè®®ï¼Œä¾¿äºäº§å“å†³ç­–ã€‚")

    if not (PROCESSED_DIR / "kpi.csv").exists():
        st.error("æœªæ‰¾åˆ°æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ: python scripts/extract_pdf_data.py && python scripts/clean_and_model.py")
        return

    kpi, peak_7d, peak_48h, daily_usage, new_users = load_data()

    # Product line filterï¼ˆæŠ¥å‘Šæ¥è‡ªæœ¬åœ° PDF æ•°æ®ï¼Œæ— éœ€ä¾§æ æ—¶é—´é€‰æ‹©ï¼‰
    product_options = list(kpi["product_line"].unique())
    selected_products = st.sidebar.multiselect("äº§å“çº¿", product_options, default=product_options)

    if not selected_products:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€æ¡äº§å“çº¿")
        return

    kpi_sel = kpi[kpi["product_line"].isin(selected_products)]
    peak_7d_sel = peak_7d[peak_7d["product_line"].isin(selected_products)]
    peak_48h_sel = peak_48h[peak_48h["product_line"].isin(selected_products)]
    daily_usage_sel = daily_usage[daily_usage["product_line"].isin(selected_products)]
    new_users_sel = new_users[new_users["product_line"].isin(selected_products)]

    # ----- æ ¸å¿ƒç»“è®ºï¼ˆå™äº‹æ‘˜è¦ï¼‰-----
    narrative = build_narrative(kpi_sel, peak_7d_sel, peak_48h_sel, daily_usage_sel, new_users_sel, selected_products)
    # è§‚å¯ŸæœŸï¼šä¼˜å…ˆä½¿ç”¨ PDF æŠ¥å‘Šæ—¶é—´èŒƒå›´ï¼ˆobservation_period.csvï¼‰ï¼Œä¸ start_time/end_time ä¸€è‡´
    obs_file = PROCESSED_DIR / "observation_period.csv"
    if obs_file.exists():
        try:
            obs_df = pd.read_csv(obs_file, encoding="utf-8")
            if not obs_df.empty and "start_date" in obs_df.columns and "end_date" in obs_df.columns:
                obs = f"{obs_df['start_date'].iloc[0]} è‡³ {obs_df['end_date'].iloc[0]}"
            else:
                obs = narrative.get("observation_period", "").strip()
        except Exception:
            obs = narrative.get("observation_period", "").strip()
    else:
        obs = narrative.get("observation_period", "").strip()
    if obs:
        st.info(f"**è§‚å¯ŸæœŸ**ï¼š{obs}")
    else:
        st.caption("è§‚å¯ŸæœŸï¼šæš‚æ— æ—¥æœŸæ•°æ®ï¼ˆè¯·å…ˆè¿è¡Œ scripts/clean_and_model.py ç”Ÿæˆ observation_period.csvï¼‰")
    with st.expander("ğŸ“Œ æ ¸å¿ƒç»“è®ºï¼ˆç‚¹å‡»å±•å¼€ï¼‰", expanded=True):
        st.markdown(narrative["summary"])

    # ----- KPI -----
    st.subheader("ä½¿ç”¨æ€»ç”¨æˆ·é‡ (Total AI Analysis Users)")
    st.caption("å„äº§å“çº¿ç´¯è®¡ç”¨æˆ·æ•°ï¼Œä¸ä¸Šæ–¹æ ¸å¿ƒç»“è®ºä¸­çš„ã€Œç´¯è®¡ç”¨æˆ·ã€ä¸€è‡´ï¼Œç”¨äºå¿«é€Ÿå¯¹æ¯”è§„æ¨¡ã€‚")
    cols = st.columns(len(selected_products))
    for i, prod in enumerate(selected_products):
        val = kpi_sel[kpi_sel["product_line"] == prod]["value"].iloc[0]
        cols[i].metric(prod, int(val))

    # ----- Row 1: Peak 7d + Peak 48h -----
    st.markdown("---")
    st.markdown("#### ä¸€ã€ä½¿ç”¨èŠ‚å¥ï¼šè¿‘7å¤©ä¸è¿‘48å°æ—¶")
    st.caption("ä¸‹é¢ä¸¤å¼ å›¾å¸®åŠ©å›ç­”ã€Œç”¨æˆ·ä»€ä¹ˆæ—¶å€™åœ¨ç”¨ã€ï¼šå·¦å›¾çœ‹è¿‘ä¸€å‘¨å„æ—¥ä»»åŠ¡é‡åˆ†å¸ƒä¸åŠŸèƒ½æ„æˆï¼Œå³å›¾çœ‹ 48 å°æ—¶å†…æŒ‰å°æ—¶çš„ä½¿ç”¨é›†ä¸­åº¦ï¼Œä¾¿äºå®‰æ’è¿è¥ä¸å®¹é‡ã€‚")
    c1, c2 = st.columns(2)

    with c1:
        st.subheader("åŠŸèƒ½ä½¿ç”¨é«˜å³° - è¿‘7å¤© (AI Feature Usage Peak - Last 7 Days)")
        # Stack by feature_id; if multiple products selected, sum task_cnt across products per date+feature
        agg_7d = peak_7d_sel.groupby(["date", "feature_id"], as_index=False)["task_cnt"].sum()
        if not agg_7d.empty:
            fig_7d = px.bar(
                agg_7d, x="date", y="task_cnt", color="feature_id",
                title="task_cnt by date (stacked)", barmode="stack",
                color_discrete_sequence=px.colors.qualitative.Set2,
            )
            fig_7d.update_layout(xaxis_title="æ—¥æœŸ", yaxis_title="task_cnt", showlegend=True)
            st.plotly_chart(fig_7d, use_container_width=True)
        else:
            st.info("æš‚æ— è¿‘7å¤©æ•°æ®")

    with c2:
        st.subheader("åŠŸèƒ½ä½¿ç”¨é«˜å³°æ—¶æ®µ - è¿‘48å°æ—¶ (Last 48 Hours)")
        if not peak_48h_sel.empty:
            agg_48h = peak_48h_sel.groupby("hour_slot", as_index=False)["task_cnt"].sum()
            fig_48h = px.line(agg_48h, x="hour_slot", y="task_cnt", markers=True)
            fig_48h.update_layout(xaxis_title="hour_slot", yaxis_title="task_cnt")
            st.plotly_chart(fig_48h, use_container_width=True)
        else:
            st.info("æš‚æ— è¿‘48å°æ—¶æ•°æ®")
    st.caption("_å·¦ï¼šæŒ‰æ—¥æœŸä¸åŠŸèƒ½å †å çš„ä»»åŠ¡é‡ï¼Œå¯çœ‹å‡ºé«˜å³°æ—¥ä¸ä¸»åŠ›åŠŸèƒ½ã€‚å³ï¼šæŒ‰å°æ—¶çš„ä½¿ç”¨é‡ï¼Œç”¨äºè¯†åˆ«é«˜å³°æ—¶æ®µã€‚_")

    # ----- Row 2: Daily usage (3 lines) + New users -----
    st.markdown("---")
    st.markdown("#### äºŒã€æ´»è·ƒä¸å¢é•¿ï¼šæ¯æ—¥ä½¿ç”¨ä¸æ–°å¢")
    st.caption("å·¦å›¾åŒæ—¶çœ‹ã€Œå¹³å‡æ¯ç”¨æˆ·æ¯æ—¥ä½¿ç”¨æ¬¡æ•°ã€ã€Œæ€»ä½¿ç”¨æ¬¡æ•°ã€ã€Œæ—¥æ´»ç”¨æˆ·æ•°ã€ä¸‰æ¡çº¿ï¼Œç”¨äºåˆ¤æ–­ç²˜æ€§ä¸è§„æ¨¡ï¼›å³å›¾çœ‹æ¯æ—¥æ–°å¢ç”¨æˆ·ï¼Œç”¨äºè¯„ä¼°æ‹‰æ–°æ•ˆæœä¸èŠ‚å¥ã€‚")
    c3, c4 = st.columns(2)

    with c3:
        st.subheader("æ¯æ—¥ä½¿ç”¨æ¬¡æ•° (Daily Usage Count)")
        if not daily_usage_sel.empty:
            agg_daily = daily_usage_sel.groupby("date", as_index=False).agg(
                avg_daily_usage_per_user=("avg_daily_usage_per_user", "mean"),
                total_usage_count=("total_usage_count", "sum"),
                dau=("dau", "sum"),
            )
            fig_daily = go.Figure()
            fig_daily.add_trace(go.Scatter(x=agg_daily["date"], y=agg_daily["avg_daily_usage_per_user"], name="å¹³å‡æ¯ç”¨æˆ·æ¯æ—¥ä½¿ç”¨æ¬¡æ•°", mode="lines+markers"))
            fig_daily.add_trace(go.Scatter(x=agg_daily["date"], y=agg_daily["total_usage_count"], name="æ€»ä½¿ç”¨æ¬¡æ•°", mode="lines+markers"))
            fig_daily.add_trace(go.Scatter(x=agg_daily["date"], y=agg_daily["dau"], name="æ—¥æ´»ç”¨æˆ·æ•°", mode="lines+markers"))
            fig_daily.update_layout(xaxis_title="æ—¥æœŸ", yaxis_title="Count", legend=dict(orientation="h"))
            st.plotly_chart(fig_daily, use_container_width=True)
        else:
            st.info("æš‚æ— æ¯æ—¥ä½¿ç”¨æ•°æ®")

    with c4:
        st.subheader("æ¯æ—¥æ–°å¢ç”¨æˆ· (New User By Day)")
        if not new_users_sel.empty:
            agg_new = new_users_sel.groupby("date", as_index=False)["new_ai_users"].sum()
            fig_new = px.line(agg_new, x="date", y="new_ai_users", markers=True)
            fig_new.update_layout(xaxis_title="æ—¥æœŸ", yaxis_title="new_ai_users")
            st.plotly_chart(fig_new, use_container_width=True)
        else:
            st.info("æš‚æ— æ¯æ—¥æ–°å¢ç”¨æˆ·æ•°æ®")
    st.caption("_å·¦ï¼šä¸‰æ¡çº¿åˆ†åˆ«å¯¹åº”äººå‡ä½¿ç”¨é¢‘æ¬¡ã€æ€»ä½¿ç”¨æ¬¡æ•°ã€æ—¥æ´»ï¼Œå¯è§‚å¯Ÿè¶‹åŠ¿æ˜¯å¦å¥åº·ã€‚å³ï¼šæ¯æ—¥æ–°å¢ç”¨æˆ·æ›²çº¿ï¼Œå¯ä¸æ¨å¹¿åŠ¨ä½œå¯¹ç…§ã€‚_")

    # ----- æ•°æ®è§£è¯»ä¸å»ºè®®ï¼ˆå™äº‹åŒ–å®šæ€§ï¼‰-----
    st.markdown("---")
    st.subheader("æ•°æ®è§£è¯»ä¸å»ºè®®")
    st.caption("åŸºäºå½“å‰ç­›é€‰æ•°æ®æç‚¼çš„ä¸»è¦å‘ç°ä¸å¯æ‰§è¡Œå»ºè®®ï¼Œä¾¿äºå½¢æˆé—­ç¯å†³ç­–ã€‚")
    st.caption("_ä»¥ä¸‹å‘ç°ä¸å»ºè®®å‡åŸºäºè§‚æµ‹æœŸæ•°æ®ï¼›å»ºè®®æŒ‰ä¼˜å…ˆçº§æ¨è¿›ï¼Œå¹¶å¯åœ¨ä¸‹æœŸæŠ¥å‘Šä¸­å¤ç›˜ã€‚_")
    col_a, col_b = st.columns(2)
    with col_a:
        st.markdown("**ä¸»è¦å‘ç°**")
        for f in narrative["findings"]:
            st.markdown(f"- {f}")
        if not narrative["findings"]:
            st.markdown("- å½“å‰æ•°æ®ä¸‹æš‚æ— é¢å¤–å‘ç°ï¼Œå¯ç»“åˆä¸Šæ–¹å›¾è¡¨åšäººå·¥è§£è¯»ã€‚")
    with col_b:
        st.markdown("**å»ºè®®ä¸‹ä¸€æ­¥**")
        for s in narrative["suggestions"]:
            st.markdown(f"- {s}")

    # ----- Data source -----
    st.divider()
    st.caption("æ•°æ®æ¥æºï¼šæ ¹ç›®å½• AI ç¯®çƒ/è¶³çƒåˆ†æçœ‹æ¿ PDFã€‚")


if __name__ == "__main__":
    main()
