#!/usr/bin/env python3
"""
AI Basketball / Soccer Analysis Dashboard â€” ç”¨æˆ·è¡Œä¸ºä¸æ•°æ®è¡¨ç°ï¼ˆå®šæ€§+å®šé‡åˆ†æï¼‰
Data source: data/processed/*.csv (from PDF extraction or mock).
Run: streamlit run app.py
"""
from pathlib import Path

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

PROJECT_ROOT = Path(__file__).resolve().parent
PROCESSED_DIR = PROJECT_ROOT / "data" / "processed"


def detect_change_segments(dates, values, min_before=2, change_ratio=1.4):
    """
    åŸºäºå®é™…æ—¶é—´åºåˆ—æ£€æµ‹æ‹ç‚¹ï¼Œåˆ’åˆ†é“ºå«/å†²çª/ç»“å±€åŒºé—´ã€‚
    ä»…ä¾æ®ä¼ å…¥çš„ dates ä¸ valuesï¼Œä¸ç¼–é€ ã€‚è‹¥æ•°æ®ç‚¹ä¸è¶³æˆ–æ— æ˜¾è‘—æ‹ç‚¹åˆ™ change_date ä¸º Noneã€‚
    """
    if dates is None or values is None or len(dates) < 3 or len(values) < 3 or len(dates) != len(values):
        if dates is not None and len(dates) > 0:
            return (dates[0], dates[-1]), None, None
        return (None, None), None, None

    dates = list(dates)
    values = list(values)
    n = len(dates)
    change_date = None
    change_idx = None

    for i in range(min_before, n):
        mean_before = sum(values[:i]) / i
        if mean_before == 0:
            continue
        ratio = values[i] / mean_before
        if ratio >= change_ratio or ratio <= (1.0 / change_ratio):
            change_date = dates[i]
            change_idx = i
            break

    if change_date is None or change_idx is None:
        segment_before = (dates[0], dates[-1])
        segment_after = None
        return segment_before, None, segment_after

    segment_before = (dates[0], dates[change_idx - 1])
    segment_after = (dates[change_idx], dates[-1])
    return segment_before, change_date, segment_after


def add_segment_regions(fig, segment_before, change_date, segment_after):
    """åœ¨æ—¶åºå›¾ä¸Šæ·»åŠ é“ºå«/å†²çª/ç»“å±€åŒºåŸŸï¼ˆä»…å½“å­˜åœ¨å®é™…åˆ†æ®µæ—¶ï¼‰ã€‚"""
    if segment_before is None or segment_before[0] is None:
        return
    x0_before, x1_before = segment_before[0], segment_before[1]
    fig.add_vrect(x0=x0_before, x1=x1_before, fillcolor="lightblue", opacity=0.1, line_width=0, annotation_text="é“ºå«", annotation_position="top left")
    if change_date is not None:
        fig.add_vline(x=change_date, line_dash="dash", line_color="orange")
    if segment_after is not None and segment_after[0] is not None and segment_after[1] is not None:
        fig.add_vrect(x0=segment_after[0], x1=segment_after[1], fillcolor="lightgreen", opacity=0.1, line_width=0, annotation_text="ç»“å±€", annotation_position="top left")


@st.cache_data
def load_data():
    kpi = pd.read_csv(PROCESSED_DIR / "kpi.csv", encoding="utf-8")
    peak_7d = pd.read_csv(PROCESSED_DIR / "peak_7d.csv", encoding="utf-8")
    peak_48h = pd.read_csv(PROCESSED_DIR / "peak_48h.csv", encoding="utf-8")
    daily_usage = pd.read_csv(PROCESSED_DIR / "daily_usage.csv", encoding="utf-8")
    new_users = pd.read_csv(PROCESSED_DIR / "new_users.csv", encoding="utf-8")
    return kpi, peak_7d, peak_48h, daily_usage, new_users


def load_release_info():
    p = PROCESSED_DIR / "release_info.csv"
    if p.exists():
        try:
            df = pd.read_csv(p, encoding="utf-8")
            if not df.empty and "region" in df.columns and "release_date" in df.columns:
                return dict(zip(df["region"], df["release_date"].astype(str)))
        except Exception:
            pass
    return {"å›½å†…": "2026-02-09", "æµ·å¤–": "2026-02-11"}


def add_release_vlines(fig, release_dates):
    if not release_dates:
        return
    for date_str, _ in release_dates:
        fig.add_vline(x=date_str, line_dash="dash", line_color="gray", line_width=1)


def build_narrative(kpi_sel, peak_7d_sel, peak_48h_sel, daily_usage_sel, new_users_sel, selected_products, show_real_users_only=False):
    """åŸºäºå½“å‰ç­›é€‰æ•°æ®ç”Ÿæˆå™äº‹æ€§è§£è¯»ä¸å»ºè®®ã€‚"""
    if show_real_users_only:
        if not new_users_sel.empty and "new_ai_users" in new_users_sel.columns:
            total_users = int(new_users_sel["new_ai_users"].sum())
            by_product_users = new_users_sel.groupby("product_line")["new_ai_users"].sum()
        else:
            total_users = 0
            by_product_users = pd.Series(dtype=float)
    else:
        total_users = int(kpi_sel["value"].sum())
        by_product_users = None
    observation_period = ""
    all_dates = []
    for df in [peak_7d_sel, daily_usage_sel, new_users_sel]:
        if not df.empty and "date" in df.columns:
            all_dates.extend(df["date"].astype(str).tolist())
    if all_dates:
        observation_period = f"{min(all_dates)} è‡³ {max(all_dates)}"
    if total_users <= 0:
        return {
            "summary": "å½“å‰ç­›é€‰ä¸‹æš‚æ— ç”¨æˆ·é‡æ•°æ®ã€‚",
            "findings": [],
            "suggestions": ["è¯·æ£€æŸ¥æ•°æ®æˆ–è°ƒæ•´äº§å“çº¿ç­›é€‰ã€‚"],
            "observation_period": observation_period,
            "setup_sentence": "å½“å‰ç­›é€‰ä¸‹æš‚æ— æ—¶åºæ•°æ®ï¼Œæ— æ³•åˆ’åˆ†é“ºå«åŒºé—´ã€‚",
            "conflict_sentence": "",
            "resolution_sentence": "",
            "change_date": None,
            "segment_before": (None, None),
            "segment_after": None,
        }

    # ----- é“ºå«-å†²çª-ç»“æœï¼šåŸºäº DAU æˆ–æ–°å¢åºåˆ—æ£€æµ‹æ‹ç‚¹ï¼ˆä»…ç”¨å®é™…æ•°æ®ï¼‰-----
    series_dates = None
    series_values = None
    series_label = ""
    if not daily_usage_sel.empty:
        agg_dau = daily_usage_sel.groupby("date")["dau"].sum()
        agg_dau = agg_dau.sort_index()
        series_dates = agg_dau.index.astype(str).tolist()
        series_values = agg_dau.tolist()
        series_label = "æ—¥æ´»"
    elif not new_users_sel.empty:
        agg_new = new_users_sel.groupby("date")["new_ai_users"].sum()
        agg_new = agg_new.sort_index()
        series_dates = agg_new.index.astype(str).tolist()
        series_values = agg_new.tolist()
        series_label = "æ–°å¢ç”¨æˆ·"

    segment_before, change_date, segment_after = (None, None), None, None
    if series_dates and series_values:
        segment_before, change_date, segment_after = detect_change_segments(series_dates, series_values)

    def _mean_in_range(dates, values, start, end):
        if start is None or end is None or not dates or not values:
            return None
        total, cnt = 0, 0
        for d, v in zip(dates, values):
            if start <= d <= end:
                total += v
                cnt += 1
        return round(total / cnt, 1) if cnt else None

    def _value_at_date(dates, values, d):
        for i, dt in enumerate(dates):
            if dt == d:
                return values[i]
        return None

    setup_sentence = ""
    conflict_sentence = ""
    resolution_sentence = ""

    if segment_before[0] is not None and segment_before[1] is not None and series_dates and series_values:
        mean_before = _mean_in_range(series_dates, series_values, segment_before[0], segment_before[1])
        if mean_before is not None:
            setup_sentence = f"**é“ºå«**ï¼šè§‚å¯ŸæœŸå‰æ®µï¼ˆ{segment_before[0]} è‡³ {segment_before[1]}ï¼‰{series_label}ç›¸å¯¹å¹³ç¨³ï¼Œæ—¥å‡çº¦ {mean_before}ã€‚"
        else:
            setup_sentence = f"**é“ºå«**ï¼šè§‚å¯ŸæœŸå‰æ®µï¼ˆ{segment_before[0]} è‡³ {segment_before[1]}ï¼‰ä¸ºå˜åŒ–å‰åŒºé—´ã€‚"

        if change_date is not None and segment_after is not None:
            val_at = _value_at_date(series_dates, series_values, change_date)
            mean_before_val = _mean_in_range(series_dates, series_values, segment_before[0], segment_before[1])
            if val_at is not None and mean_before_val is not None and mean_before_val != 0:
                pct = round((val_at - mean_before_val) / mean_before_val * 100, 1)
                direction = "ä¸Šå‡" if pct > 0 else "ä¸‹é™"
                conflict_sentence = f"**å†²çª**ï¼š{change_date} å‡ºç°æ˜æ˜¾æ‹ç‚¹ï¼Œå½“æ—¥{series_label}ä¸º {val_at}ï¼Œè¾ƒå‰æ®µå‡å€¼ {mean_before_val} {direction} {abs(pct)}%ï¼ˆæ•°æ®è¡¨ç°ï¼‰ã€‚"
            else:
                conflict_sentence = f"**å†²çª**ï¼š{change_date} å‡ºç°æ˜æ˜¾æ‹ç‚¹ï¼Œå½“æ—¥{series_label}ä¸º {val_at}ï¼Œä¸å‰æ®µå½¢æˆè½¬æŠ˜ï¼ˆæ•°æ®è¡¨ç°ï¼‰ã€‚"

            mean_after = _mean_in_range(series_dates, series_values, segment_after[0], segment_after[1])
            if mean_after is not None and mean_before_val is not None:
                resolution_sentence = f"**ç»“å±€**ï¼šæ‹ç‚¹åï¼ˆ{segment_after[0]} è‡³ {segment_after[1]}ï¼‰æ—¥å‡{series_label}çº¦ {mean_after}ï¼Œè¾ƒå‰æ®µå‡å€¼ {mean_before_val} æŠ¬å‡ã€‚" if mean_after >= mean_before_val else f"**ç»“å±€**ï¼šæ‹ç‚¹åï¼ˆ{segment_after[0]} è‡³ {segment_after[1]}ï¼‰æ—¥å‡{series_label}çº¦ {mean_after}ï¼Œè¾ƒå‰æ®µå‡å€¼ {mean_before_val} å›è½ã€‚"
            else:
                resolution_sentence = f"**ç»“å±€**ï¼šæ‹ç‚¹åï¼ˆ{segment_after[0]} è‡³ {segment_after[1]}ï¼‰ä¸ºç»“æœåŒºé—´ï¼Œæ•°æ®è§ä¸Šå›¾ã€‚"
        else:
            conflict_sentence = "**å†²çª**ï¼šè§‚æµ‹æœŸå†…æ•´ä½“å¹³ç¨³ï¼Œæœªå‘ç°æ˜æ˜¾æ‹ç‚¹ï¼›æˆ–æ•°æ®ç‚¹ä¸è¶³ï¼Œæœªæ£€æµ‹åˆ°æ‹ç‚¹ã€‚"
            resolution_sentence = "**ç»“å±€**ï¼šæ•´æ®µè§‚æµ‹æœŸå‘ˆå¹³ç¨³æ€åŠ¿ï¼Œæ— æ‹ç‚¹ååŒºé—´ã€‚"
    else:
        setup_sentence = "**é“ºå«**ï¼šæ—¶åºæ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ’åˆ†é“ºå«åŒºé—´ã€‚"
        conflict_sentence = "**å†²çª**ï¼šæ•°æ®ç‚¹ä¸è¶³ï¼Œæœªæ£€æµ‹åˆ°æ‹ç‚¹ã€‚"
        resolution_sentence = "**ç»“å±€**ï¼šæš‚æ— ã€‚"

    # ----- ç»Ÿä¸€è®¡ç®—å…³é”®æŒ‡æ ‡ï¼ˆä¾› findings ä¸ suggestions å…±ç”¨ï¼‰-----
    lead_product, lead_count, lead_pct = None, None, None
    if len(selected_products) >= 2:
        if by_product_users is not None:
            a = float(by_product_users.get(selected_products[0], 0))
            b = float(by_product_users.get(selected_products[1], 0))
        else:
            a = kpi_sel[kpi_sel["product_line"] == selected_products[0]]["value"].sum()
            b = kpi_sel[kpi_sel["product_line"] == selected_products[1]]["value"].sum()
        if a + b > 0:
            lead_product = selected_products[0] if a >= b else selected_products[1]
            lead_count = int(a if lead_product == selected_products[0] else b)
            lead_pct = round(100 * lead_count / total_users, 1)

    dau_mean, max_dau, max_dau_date = None, None, None
    if not daily_usage_sel.empty:
        dau_mean = float(daily_usage_sel.groupby("date")["dau"].sum().mean())
        max_dau = int(daily_usage_sel["dau"].max())
        max_dau_date = daily_usage_sel.loc[daily_usage_sel["dau"].idxmax(), "date"]

    total_new, zero_days, new_peak = None, None, None
    if not new_users_sel.empty:
        new_by_date = new_users_sel.groupby("date")["new_ai_users"].sum()
        total_new = int(new_by_date.sum())
        zero_days = int((new_by_date == 0).sum())
        new_peak = int(new_users_sel["new_ai_users"].max())

    peak_date, peak_val = None, None
    if not peak_7d_sel.empty:
        agg7 = peak_7d_sel.groupby("date", as_index=False)["task_cnt"].sum()
        if not agg7.empty:
            peak_date = agg7.loc[agg7["task_cnt"].idxmax(), "date"]
            peak_val = int(agg7["task_cnt"].max())

    busy_slot = None
    if not peak_48h_sel.empty and peak_48h_sel["task_cnt"].sum() > 0:
        agg48 = peak_48h_sel.groupby("hour_slot")["task_cnt"].sum()
        busy_slot = agg48.idxmax()

    # ----- æ‘˜è¦ï¼ˆä¿æŒä¸å˜ï¼‰-----
    product_breakdown = []
    for p in selected_products:
        if by_product_users is not None:
            v = float(by_product_users.get(p, 0))
        else:
            v = kpi_sel[kpi_sel["product_line"] == p]["value"].sum()
        if v > 0:
            pct = round(100 * v / total_users, 1)
            product_breakdown.append(f"{p} {int(v)} äººï¼ˆ{pct}%ï¼‰")
    summary_parts = [f"æœ¬å‘¨æœŸå†…ï¼Œæ‰€é€‰äº§å“çº¿**ç´¯è®¡ç”¨æˆ·å…± {total_users} äºº**"]
    if product_breakdown:
        summary_parts.append("ï¼Œå…¶ä¸­ " + "ã€".join(product_breakdown) + "ã€‚")
    else:
        summary_parts.append("ã€‚")
    if peak_date is not None:
        summary_parts.append(f"**è¿‘7å¤©åŠŸèƒ½ä½¿ç”¨é«˜å³°**å‡ºç°åœ¨ {peak_date}ï¼ˆå½“æ—¥ä»»åŠ¡é‡ {peak_val}ï¼‰ã€‚")
    if max_dau is not None:
        summary_parts.append(f"**æ—¥æ´»å³°å€¼**ä¸º {max_dau} äººï¼ˆ{max_dau_date}ï¼‰ã€‚")
    if total_new is not None:
        summary_parts.append(f"è§‚æµ‹æœŸå†…**æ–°å¢ç”¨æˆ·åˆè®¡ {total_new} äºº**ï¼Œå•æ—¥æ–°å¢æœ€é«˜ {new_peak} äººã€‚")
    summary = " ".join(summary_parts)

    # ----- ä¸»è¦å‘ç°ï¼šç»“è®º + æ•°æ® + ä¸šåŠ¡å«ä¹‰ -----
    findings = []
    if lead_product is not None:
        findings.append(
            f"**äº§å“çº¿å¯¹æ¯”**ï¼š{lead_product} é¢†å…ˆï¼ˆå…± {lead_count} äººï¼Œå  {lead_pct}%ï¼‰ï¼Œæ˜¯å½“å‰ä¸»è¦ç”¨æˆ·æ¥æºï¼Œèµ„æºå€¾æ–œæœ‰æ•°æ®æ”¯æ’‘ï¼›å¯è€ƒè™‘ä»è¯¥çº¿å‘å¦ä¸€æ¡çº¿å¯¼æµæ‹‰æ–°ã€‚"
        )
    if dau_mean is not None:
        peak_part = f"ï¼Œå³°å€¼ {max_dau} äººï¼ˆ{max_dau_date}ï¼‰" if max_dau is not None else ""
        findings.append(
            f"**æ´»è·ƒåº¦**ï¼šè§‚æµ‹æœŸå†…æ—¥å‡æ´»è·ƒçº¦ {dau_mean:.1f} äºº{peak_part}ï¼›æ•´ä½“è§„æ¨¡ä»å°ã€æ³¢åŠ¨æ˜æ˜¾ï¼Œç•™å­˜ä¸ä¹ æƒ¯å°šæœªç¨³å®šï¼Œéœ€é€šè¿‡æ´»åŠ¨ä¸è§¦è¾¾æå‡ã€‚"
        )
    if zero_days is not None and zero_days > 0:
        findings.append(
            f"**æ–°å¢èŠ‚å¥**ï¼šè§‚æµ‹æœŸå†…å…± {zero_days} å¤©é›¶æ–°å¢ã€ç´¯è®¡æ–°å¢ {total_new} äººï¼›æ‹‰æ–°ä¸ç¨³å®šï¼Œéœ€æ’æŸ¥æ›å…‰ä¸è½¬åŒ–æ¼æ–—ã€‚"
        )
    if busy_slot is not None:
        findings.append(
            f"**48 å°æ—¶é«˜å³°**ï¼šä½¿ç”¨é›†ä¸­åœ¨ã€Œ{busy_slot}ã€æ—¶æ®µï¼›å»ºè®®åœ¨è¯¥æ—¶æ®µä¿éšœæœåŠ¡å®¹é‡ä¸ç¨³å®šæ€§ï¼Œå¹¶å¯åšè½»é‡æ¨é€ä»¥æå‡è½¬åŒ–ã€‚"
        )

    # ----- å»ºè®®ä¸‹ä¸€æ­¥ï¼šç”±æ•°æ®ä¸å‘ç°åŠ¨æ€ç”Ÿæˆï¼ˆä¾æ® + å…·ä½“åŠ¨ä½œï¼‰-----
    suggestions = []
    if zero_days is not None and zero_days > 0:
        suggestions.append(
            f"**æ‹‰æ–°**ï¼šåŸºäºè§‚æµ‹æœŸå†… {zero_days} å¤©é›¶æ–°å¢ã€ç´¯è®¡ {total_new} äººæ–°å¢ï¼Œå»ºè®®æœ¬å‘¨å†…å®Œæˆå„æ¸ é“æ›å…‰ä¸è½¬åŒ–æ¼æ–—æ‹†è§£ï¼Œå¹¶è®¾å®šä¸‹æœˆæ‹‰æ–°ç›®æ ‡ã€è½å®åˆ°æ¸ é“è´Ÿè´£äººã€‚"
        )
    if busy_slot is not None:
        suggestions.append(
            f"**èµ„æºä¸èŠ‚å¥**ï¼šä½¿ç”¨é›†ä¸­åœ¨ã€Œ{busy_slot}ã€ï¼Œå»ºè®®åœ¨è¯¥æ—¶æ®µä¿è¯æœåŠ¡å®¹é‡å¹¶å®‰æ’è½»é‡æ¨é€ï¼Œä»¥æå‡è½¬åŒ–ã€‚"
        )
    if lead_product is not None:
        other = [p for p in selected_products if p != lead_product]
        other_line = other[0] if other else "å¦ä¸€æ¡çº¿"
        suggestions.append(
            f"**äº§å“çº¿**ï¼š{lead_product} å½“å‰é¢†å…ˆï¼ˆ{lead_count} äººï¼Œ{lead_pct}%ï¼‰ï¼Œå»ºè®®ä¼˜å…ˆä¿éšœè¯¥çº¿èµ„æºä¸ä½“éªŒï¼Œå¹¶è®¾è®¡å‘{other_line}çš„å¯¼æµå®éªŒï¼ˆå…¥å£ã€æ´»åŠ¨æˆ–æ–‡æ¡ˆï¼‰ã€‚"
        )
    if dau_mean is not None:
        suggestions.append(
            f"**æ´»è·ƒä¸ç•™å­˜**ï¼šæ—¥å‡æ´»è·ƒçº¦ {dau_mean:.1f} äººï¼Œå»ºè®®è®¾å®šç•™å­˜ä¸å”¤é†’èŠ‚å¥ï¼ˆå¦‚æ¯å‘¨ä¸€æ¬¡è§¦è¾¾ï¼‰ï¼Œå¹¶è·Ÿè¸ªæ¬¡å‘¨ç•™å­˜ä»¥è¯„ä¼°æ´»åŠ¨æ•ˆæœã€‚"
        )
    if peak_date is not None:
        suggestions.append(
            f"**è¿‘ 7 å¤©èŠ‚å¥**ï¼šé«˜å³°æ—¥åœ¨ {peak_date}ï¼ˆä»»åŠ¡é‡ {peak_val}ï¼‰ï¼Œå»ºè®®å°†åŠŸèƒ½ä¸è¿è¥èµ„æºå‘è¯¥æ—¥å‰åé›†ä¸­ï¼Œä½å³°æ—¥åšå®šå‘å¬å›ï¼ˆæ¨é€ã€æ´»åŠ¨ï¼‰ã€‚"
        )
    if not suggestions:
        suggestions.append("å½“å‰æ•°æ®ä¸‹æš‚æ— å¼ºæ•°æ®æ”¯æ’‘çš„ä¸“é¡¹å»ºè®®ï¼Œå¯ç»“åˆä¸Šæ–¹å›¾è¡¨åšäººå·¥è§£è¯»å¹¶è®¾å®šä¸‹æœŸå¤ç›˜æŒ‡æ ‡ã€‚")

    return {
        "summary": summary,
        "findings": findings,
        "suggestions": suggestions,
        "observation_period": observation_period,
        "setup_sentence": setup_sentence,
        "conflict_sentence": conflict_sentence,
        "resolution_sentence": resolution_sentence,
        "change_date": change_date,
        "segment_before": segment_before,
        "segment_after": segment_after,
        # ä¾›ç®¡ç†å±‚è§†å›¾ä½¿ç”¨çš„å…³é”®æ•°å€¼
        "total_users": total_users,
        "dau_mean": dau_mean,
        "max_dau": max_dau,
        "total_new": total_new,
        "zero_days": zero_days,
        "new_peak": new_peak,
        "busy_slot": busy_slot,
        "lead_product": lead_product,
        "lead_count": lead_count,
        "lead_pct": lead_pct,
    }


def compute_status_tags(narrative):
    """
    åŸºäº narrative ä¸­çš„å…³é”®æ•°å€¼ï¼Œç”Ÿæˆç»™ç®¡ç†å±‚çœ‹çš„ã€Œè§„æ¨¡ / æ´»è·ƒ / æ‹‰æ–°ã€æ ‡ç­¾ã€‚
    ä»…åšç²—é¢—ç²’åº¦å½’ç±»ï¼Œé¿å…è¿‡åº¦è§£è¯»å…·ä½“æ•°å€¼ã€‚
    """
    total_users = narrative.get("total_users")
    dau_mean = narrative.get("dau_mean")
    max_dau = narrative.get("max_dau")
    total_new = narrative.get("total_new")
    zero_days = narrative.get("zero_days")

    # è§„æ¨¡æ ‡ç­¾
    if not isinstance(total_users, (int, float)) or total_users is None or total_users <= 0:
        scale = "è§„æ¨¡ï¼šæš‚æ— æ•°æ®"
    elif total_users < 500:
        scale = "è§„æ¨¡ï¼šå°è§„æ¨¡è¯•è¿è¡Œ"
    elif total_users < 5000:
        scale = "è§„æ¨¡ï¼šåœ¨æ‰©å¼ ä¸­"
    else:
        scale = "è§„æ¨¡ï¼šå·²æˆå‹"

    # æ´»è·ƒæ ‡ç­¾ï¼ˆç²—ç•¥çœ‹æ—¥å‡æ´»è·ƒä¸å³°å€¼ï¼‰
    if dau_mean is None:
        active = "æ´»è·ƒï¼šæš‚æ— æ•°æ®"
    else:
        if max_dau and dau_mean and max_dau / max_dau if max_dau else 1:
            # ä½¿ç”¨æ—¥å‡æ´»è·ƒå æ€»ç”¨æˆ·çš„æ¯”ä¾‹ç²—ç•¥åˆ¤æ–­æ¸—é€
            if total_users and total_users > 0:
                penetration = dau_mean / total_users
                if penetration >= 0.5:
                    active = "æ´»è·ƒï¼šé«˜æ¸—é€"
                elif penetration >= 0.2:
                    active = "æ´»è·ƒï¼šä¸­ç­‰"
                else:
                    active = "æ´»è·ƒï¼šå¾…æå‡"
            else:
                active = "æ´»è·ƒï¼šå¾…è§‚å¯Ÿ"
        else:
            active = "æ´»è·ƒï¼šå¾…è§‚å¯Ÿ"

    # æ‹‰æ–°æ ‡ç­¾
    if total_new is None:
        growth = "æ‹‰æ–°ï¼šæš‚æ— æ•°æ®"
    elif total_new == 0:
        growth = "æ‹‰æ–°ï¼šæš‚æ— æ–°å¢"
    elif zero_days is not None and zero_days > 0:
        growth = "æ‹‰æ–°ï¼šèŠ‚å¥ä¸ç¨³å®š"
    else:
        growth = "æ‹‰æ–°ï¼šèŠ‚å¥è¾ƒç¨³å®š"

    return scale, active, growth


def main():
    st.set_page_config(page_title="AI åˆ†æçœ‹æ¿", layout="wide")
    st.title("AI ç¯®çƒ / è¶³çƒåˆ†æçœ‹æ¿")
    st.caption("ç®¡ç†å±‚è§†å›¾ï¼šå¿«é€Ÿäº†è§£è§„æ¨¡ã€æ´»è·ƒä¸æ‹‰æ–°è¡¨ç°")
    st.markdown("æœ¬æŠ¥å‘Šå›´ç»•ä¸‰ä¸ªé—®é¢˜ï¼š**ç°åœ¨è§„æ¨¡ä¸å¥åº·åº¦å¦‚ä½•ï¼Ÿç”¨æˆ·ä»€ä¹ˆæ—¶å€™åœ¨ç”¨ï¼Ÿä¸‹ä¸€æ­¥è¦åšä»€ä¹ˆï¼Ÿ** æ¥ç»„ç»‡æ•°æ®ä¸ç»“è®ºã€‚")

    if not (PROCESSED_DIR / "kpi.csv").exists():
        st.error("æœªæ‰¾åˆ°æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ: python scripts/extract_pdf_data.py && python scripts/clean_and_model.py")
        return

    kpi, peak_7d, peak_48h, daily_usage, new_users = load_data()

    # Product line filterï¼ˆæŠ¥å‘Šæ¥è‡ªæœ¬åœ° PDF æ•°æ®ï¼Œæ— éœ€ä¾§æ æ—¶é—´é€‰æ‹©ï¼‰
    product_options = list(kpi["product_line"].unique())
    view_mode = st.sidebar.selectbox(
        "é¢„è®¾è§†å›¾",
        ["ç®¡ç†å±‚æ±‡æ€»è§†å›¾", "è‡ªå®šä¹‰ç­›é€‰ï¼ˆé«˜çº§ï¼‰"],
        index=0,
        help="ç®¡ç†å±‚æ±‡æ€»è§†å›¾ï¼šæ¨èè®¾ç½®ï¼›è‡ªå®šä¹‰ç­›é€‰ï¼šæŒ‰äº§å“çº¿ä¸æ•°æ®èŒƒå›´è‡ªç”±ç»„åˆã€‚",
    )
    selected_products = st.sidebar.multiselect("äº§å“çº¿", product_options, default=product_options)

    data_range = st.sidebar.radio(
        "æ•°æ®èŒƒå›´",
        ["å±•ç¤ºå…¨é‡æ•°æ®", "ä»…å±•ç¤ºä¸Šçº¿åçœŸå®ç”¨æˆ·æ•°æ®"],
        index=1 if view_mode == "ç®¡ç†å±‚æ±‡æ€»è§†å›¾" else 0,
    )
    show_real_users_only = data_range == "ä»…å±•ç¤ºä¸Šçº¿åçœŸå®ç”¨æˆ·æ•°æ®"

    # é¢„è®¾è§†å›¾ä¸‹çš„æœ‰æ•ˆç­›é€‰
    if view_mode == "ç®¡ç†å±‚æ±‡æ€»è§†å›¾":
        effective_selected_products = product_options
        effective_show_real_users_only = True
    else:
        effective_selected_products = selected_products
        effective_show_real_users_only = show_real_users_only
    release_by_region = load_release_info()
    cutoff_date = release_by_region.get("å›½å†…", "2026-02-09")

    if not effective_selected_products:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€æ¡äº§å“çº¿")
        return

    kpi_sel = kpi[kpi["product_line"].isin(effective_selected_products)]
    peak_7d_sel = peak_7d[peak_7d["product_line"].isin(effective_selected_products)]
    peak_48h_sel = peak_48h[peak_48h["product_line"].isin(effective_selected_products)]
    daily_usage_sel = daily_usage[daily_usage["product_line"].isin(effective_selected_products)]
    new_users_sel = new_users[new_users["product_line"].isin(effective_selected_products)]

    if effective_show_real_users_only:
        if "date" in daily_usage_sel.columns:
            daily_usage_sel = daily_usage_sel[daily_usage_sel["date"] >= cutoff_date]
        if "date" in new_users_sel.columns:
            new_users_sel = new_users_sel[new_users_sel["date"] >= cutoff_date]
        if "date" in peak_7d_sel.columns:
            peak_7d_sel = peak_7d_sel[peak_7d_sel["date"] >= cutoff_date]
        if not peak_48h_sel.empty and "hour_slot" in peak_48h_sel.columns:
            try:
                slot_dates = pd.to_datetime(peak_48h_sel["hour_slot"], errors="coerce")
                peak_48h_sel = peak_48h_sel.loc[slot_dates.dt.strftime("%Y-%m-%d") >= cutoff_date]
            except Exception:
                pass

    # ----- æ ¸å¿ƒç»“è®ºï¼ˆå™äº‹æ‘˜è¦ï¼‰-----
    narrative = build_narrative(
        kpi_sel,
        peak_7d_sel,
        peak_48h_sel,
        daily_usage_sel,
        new_users_sel,
        effective_selected_products,
        show_real_users_only=effective_show_real_users_only,
    )
    # è§‚å¯ŸæœŸï¼šä¼˜å…ˆä½¿ç”¨ PDF æŠ¥å‘Šæ—¶é—´èŒƒå›´ï¼ˆobservation_period.csvï¼‰ï¼Œä¸ start_time/end_time ä¸€è‡´
    obs_file = PROCESSED_DIR / "observation_period.csv"
    if obs_file.exists():
        try:
            obs_df = pd.read_csv(obs_file, encoding="utf-8")
            if not obs_df.empty and "start_date" in obs_df.columns and "end_date" in obs_df.columns:
                obs = f"{obs_df['start_date'].iloc[0]} è‡³ {obs_df['end_date'].iloc[0]}"
            else:
                obs = narrative.get("observation_period", "").strip()
        except Exception:
            obs = narrative.get("observation_period", "").strip()
    else:
        obs = narrative.get("observation_period", "").strip()
    if obs:
        st.info(f"**è§‚å¯ŸæœŸ**ï¼š{obs}")
        st.caption("æœ¬åŠŸèƒ½äºå›½å†… 2æœˆ9æ—¥ã€æµ·å¤– 2æœˆ11æ—¥ æ­£å¼ç»™åˆ°ç”¨æˆ·ã€‚")
        if not effective_show_real_users_only:
            st.caption("å…¨é‡æ•°æ®æ¨¡å¼ä¸‹ï¼Œä¸‹æ–¹ã€Œæ¯æ—¥ä½¿ç”¨æ¬¡æ•°ã€ã€Œæ¯æ—¥æ–°å¢ç”¨æˆ·ã€å›¾ä¸­ç«–çº¿ä¸ºè¯¥æ—¶é—´ç‚¹ã€‚")
    else:
        st.caption("è§‚å¯ŸæœŸï¼šæš‚æ— æ—¥æœŸæ•°æ®ï¼ˆè¯·å…ˆè¿è¡Œ scripts/clean_and_model.py ç”Ÿæˆ observation_period.csvï¼‰")
    if effective_show_real_users_only:
        st.info("å½“å‰ KPIã€ç»“è®ºä¸å›¾è¡¨å‡ä»…å«ä¸Šçº¿æ—¥ï¼ˆå›½å†… 2æœˆ9æ—¥ / æµ·å¤– 2æœˆ11æ—¥ï¼‰èµ·æ•°æ®ã€‚")

    # æœ¬æœŸç»“è®ºæ ‡ç­¾æ 
    scale_tag, active_tag, growth_tag = compute_status_tags(narrative)
    tag_cols = st.columns(3)
    tag_cols[0].markdown(f"**{scale_tag}**")
    tag_cols[1].markdown(f"**{active_tag}**")
    tag_cols[2].markdown(f"**{growth_tag}**")

    # ç®¡ç†å±‚æ€»è§ˆï¼šå·¦ä¾§ç»“è®ºï¼Œå³ä¾§è¡ŒåŠ¨
    st.markdown("---")
    overview_left, overview_right = st.columns([2, 1])
    with overview_left:
        st.subheader("ç®¡ç†å±‚æ€»è§ˆ")
        st.markdown(narrative["summary"])
        key_findings = narrative.get("findings", [])[:2]
        if key_findings:
            st.markdown("**å…³é”®ç»“è®º**")
            for f in key_findings:
                st.markdown(f"- {f}")
    with overview_right:
        st.subheader("ä¸‹ä¸€æ­¥è¡ŒåŠ¨")
        suggestions = narrative.get("suggestions", [])[:5]
        if suggestions:
            for s in suggestions:
                st.markdown(f"- {s}")
        else:
            st.caption("å½“å‰æ•°æ®ä¸‹æš‚æ— å¼ºæ•°æ®æ”¯æ’‘çš„ä¸“é¡¹è¡ŒåŠ¨å»ºè®®ã€‚")

    with st.expander("ğŸ“Œ å™äº‹åˆ†æï¼ˆé“ºå«-å†²çª-ç»“æœï¼‰", expanded=False):
        if narrative.get("setup_sentence"):
            st.markdown(narrative["setup_sentence"])
        if narrative.get("conflict_sentence"):
            st.markdown(narrative["conflict_sentence"])
        if narrative.get("resolution_sentence"):
            st.markdown(narrative["resolution_sentence"])

    # ----- KPI -----
    if effective_show_real_users_only:
        st.subheader("ä¸Šçº¿åç´¯è®¡æ–°å¢ç”¨æˆ·")
        st.caption("ä»…ç»Ÿè®¡ä¸Šçº¿æ—¥ï¼ˆå›½å†… 2æœˆ9æ—¥ / æµ·å¤– 2æœˆ11æ—¥ï¼‰èµ·æ–°å¢ç”¨æˆ·ï¼Œä¸æ ¸å¿ƒç»“è®ºä¸€è‡´ã€‚")
        real_new_by_product = new_users_sel.groupby("product_line")["new_ai_users"].sum() if not new_users_sel.empty else pd.Series(dtype=float)
        cols = st.columns(len(effective_selected_products))
        for i, prod in enumerate(effective_selected_products):
            val = int(real_new_by_product.get(prod, 0))
            cols[i].metric(prod, val)
    else:
        st.subheader("ä½¿ç”¨æ€»ç”¨æˆ·é‡ (Total AI Analysis Users)")
        st.caption("å„äº§å“çº¿ç´¯è®¡ç”¨æˆ·æ•°ï¼Œä¸ä¸Šæ–¹ç®¡ç†å±‚æ€»è§ˆä¸­çš„ã€Œç´¯è®¡ç”¨æˆ·ã€ä¸€è‡´ï¼Œç”¨äºå¿«é€Ÿå¯¹æ¯”è§„æ¨¡ã€‚")
        cols = st.columns(len(effective_selected_products))
        for i, prod in enumerate(effective_selected_products):
            val = kpi_sel[kpi_sel["product_line"] == prod]["value"].iloc[0]
            cols[i].metric(prod, int(val))

    # ----- Row 1: Peak 7d + Peak 48h -----
    st.markdown("---")
    st.markdown("#### ä¸€ã€ä½¿ç”¨èŠ‚å¥ï¼šè¿‘7å¤©ä¸è¿‘48å°æ—¶")
    st.caption("å›ç­”ã€Œç”¨æˆ·ä»€ä¹ˆæ—¶å€™åœ¨ç”¨ï¼Ÿã€ï¼šå·¦å›¾çœ‹è¿‘ä¸€å‘¨çš„é«˜å³°æ—¥ä¸ä¸»åŠ›åŠŸèƒ½ï¼Œå³å›¾çœ‹è¿‘ 48 å°æ—¶å†…çš„ä½¿ç”¨é«˜å³°æ—¶æ®µï¼Œä¾¿äºå®‰æ’è¿è¥ä¸å®¹é‡ã€‚")
    c1, c2 = st.columns(2)

    with c1:
        st.subheader("è¿‘ 7 å¤©ï¼šå“ªå¤©æœ€å¿™ï¼Œè°åœ¨è´¡çŒ®ä»»åŠ¡ï¼Ÿ")
        # Stack by feature_id; if multiple products selected, sum task_cnt across products per date+feature
        agg_7d = peak_7d_sel.groupby(["date", "feature_id"], as_index=False)["task_cnt"].sum()
        if not agg_7d.empty:
            fig_7d = px.bar(
                agg_7d, x="date", y="task_cnt", color="feature_id",
                title="task_cnt by date (stacked)", barmode="stack",
                color_discrete_sequence=px.colors.qualitative.Set2,
            )
            fig_7d.update_layout(xaxis_title="æ—¥æœŸ", yaxis_title="task_cnt", showlegend=True)
            st.plotly_chart(fig_7d, use_container_width=True)
        else:
            st.info("æš‚æ— è¿‘7å¤©æ•°æ®")

    with c2:
        st.subheader("è¿‘ 48 å°æ—¶ï¼šä½¿ç”¨é«˜å³°åœ¨ä»€ä¹ˆæ—¶å€™ï¼Ÿ")
        if not peak_48h_sel.empty:
            agg_48h = peak_48h_sel.groupby("hour_slot", as_index=False)["task_cnt"].sum()
            fig_48h = px.line(agg_48h, x="hour_slot", y="task_cnt", markers=True)
            fig_48h.update_layout(xaxis_title="hour_slot", yaxis_title="task_cnt")
            st.plotly_chart(fig_48h, use_container_width=True)
        else:
            st.info("æš‚æ— è¿‘48å°æ—¶æ•°æ®")
    st.caption("_å·¦ï¼šæŒ‰æ—¥æœŸä¸åŠŸèƒ½å †å çš„ä»»åŠ¡é‡ï¼Œå¯çœ‹å‡ºé«˜å³°æ—¥ä¸ä¸»åŠ›åŠŸèƒ½ã€‚å³ï¼šæŒ‰å°æ—¶çš„ä½¿ç”¨é‡ï¼Œç”¨äºè¯†åˆ«é«˜å³°æ—¶æ®µã€‚_")

    # ----- Row 2: Daily usage (3 lines) + New users -----
    st.markdown("---")
    st.markdown("#### äºŒã€æ´»è·ƒä¸å¢é•¿ï¼šæ¯æ—¥ä½¿ç”¨ä¸æ–°å¢")
    st.caption("å·¦å›¾åŒæ—¶çœ‹ã€Œå¹³å‡æ¯ç”¨æˆ·æ¯æ—¥ä½¿ç”¨æ¬¡æ•°ã€ã€Œæ€»ä½¿ç”¨æ¬¡æ•°ã€ã€Œæ—¥æ´»ç”¨æˆ·æ•°ã€ä¸‰æ¡çº¿ï¼Œç»¼åˆåˆ¤æ–­ç²˜æ€§ä¸è§„æ¨¡ï¼›å³å›¾çœ‹æ¯æ—¥æ–°å¢ç”¨æˆ·ï¼Œç”¨äºè¯„ä¼°æ‹‰æ–°æ•ˆæœä¸èŠ‚å¥æ˜¯å¦ç¨³å®šã€‚")
    c3, c4 = st.columns(2)

    with c3:
        st.subheader("æ¯æ—¥ä½¿ç”¨æ¬¡æ•° (Daily Usage Count)")
        if not daily_usage_sel.empty:
            agg_daily = daily_usage_sel.groupby("date", as_index=False).agg(
                avg_daily_usage_per_user=("avg_daily_usage_per_user", "mean"),
                total_usage_count=("total_usage_count", "sum"),
                dau=("dau", "sum"),
            )
            fig_daily = go.Figure()
            fig_daily.add_trace(go.Scatter(x=agg_daily["date"], y=agg_daily["avg_daily_usage_per_user"], name="å¹³å‡æ¯ç”¨æˆ·æ¯æ—¥ä½¿ç”¨æ¬¡æ•°", mode="lines+markers"))
            fig_daily.add_trace(go.Scatter(x=agg_daily["date"], y=agg_daily["total_usage_count"], name="æ€»ä½¿ç”¨æ¬¡æ•°", mode="lines+markers"))
            fig_daily.add_trace(go.Scatter(x=agg_daily["date"], y=agg_daily["dau"], name="æ—¥æ´»ç”¨æˆ·æ•°", mode="lines+markers"))
            fig_daily.update_layout(xaxis_title="æ—¥æœŸ", yaxis_title="Count", legend=dict(orientation="h"))
            add_segment_regions(fig_daily, narrative["segment_before"], narrative["change_date"], narrative["segment_after"])
            if not show_real_users_only:
                add_release_vlines(fig_daily, [(release_by_region.get("å›½å†…", "2026-02-09"), "å›½å†…"), (release_by_region.get("æµ·å¤–", "2026-02-11"), "æµ·å¤–")])
            st.plotly_chart(fig_daily, use_container_width=True)
        else:
            st.info("æš‚æ— æ¯æ—¥ä½¿ç”¨æ•°æ®")

    with c4:
        st.subheader("æ¯æ—¥æ–°å¢ç”¨æˆ· (New User By Day)")
        if not new_users_sel.empty:
            agg_new = new_users_sel.groupby("date", as_index=False)["new_ai_users"].sum()
            fig_new = px.line(agg_new, x="date", y="new_ai_users", markers=True)
            fig_new.update_layout(xaxis_title="æ—¥æœŸ", yaxis_title="new_ai_users")
            add_segment_regions(fig_new, narrative["segment_before"], narrative["change_date"], narrative["segment_after"])
            if not effective_show_real_users_only:
                add_release_vlines(fig_new, [(release_by_region.get("å›½å†…", "2026-02-09"), "å›½å†…"), (release_by_region.get("æµ·å¤–", "2026-02-11"), "æµ·å¤–")])
            st.plotly_chart(fig_new, use_container_width=True)

            # è‡ªåŠ¨ç”Ÿæˆçš„æ‹‰æ–°ç»“è®ºï¼Œå¸®åŠ©ç®¡ç†å±‚å¿«é€Ÿè¯»æ‡‚æ–°å¢èŠ‚å¥
            zero_days = narrative.get("zero_days")
            total_new = narrative.get("total_new")
            if total_new is not None:
                if zero_days is not None and zero_days > 0:
                    st.caption(f"è§‚æµ‹æœŸå†…å…±æ–°å¢ {total_new} äººï¼Œå…¶ä¸­æœ‰ {zero_days} å¤©ä¸ºé›¶æ–°å¢ï¼Œæ‹‰æ–°èŠ‚å¥åä¸ç¨³å®šã€‚")
                else:
                    st.caption(f"è§‚æµ‹æœŸå†…å…±æ–°å¢ {total_new} äººï¼Œå‡ ä¹æ¯å¤©éƒ½æœ‰æ–°å¢ï¼Œæ‹‰æ–°èŠ‚å¥ç›¸å¯¹ç¨³å®šã€‚")
        else:
            st.info("æš‚æ— æ¯æ—¥æ–°å¢ç”¨æˆ·æ•°æ®")
    st.caption("_å·¦ï¼šäººå‡ä½¿ç”¨é¢‘æ¬¡ + æ€»ä½¿ç”¨æ¬¡æ•° + æ—¥æ´»ï¼Œç”¨äºç»¼åˆåˆ¤æ–­ç²˜æ€§ä¸è§„æ¨¡ã€‚å³ï¼šæ¯æ—¥æ–°å¢ç”¨æˆ·æ›²çº¿ï¼Œå¯ä¸æ¨å¹¿åŠ¨ä½œå¯¹ç…§ã€‚_" + (" ç«–çº¿ï¼šå›½å†… 2æœˆ9æ—¥ã€æµ·å¤– 2æœˆ11æ—¥ï¼ˆä¸Šçº¿æ—¥ï¼‰ã€‚" if not effective_show_real_users_only else ""))

    # ----- æ•°æ®è§£è¯»ä¸å»ºè®®ï¼ˆå™äº‹åŒ–å®šæ€§ï¼‰-----
    st.markdown("---")
    st.subheader("æ•°æ®è§£è¯»ä¸å»ºè®®")
    st.caption("åŸºäºå½“å‰ç­›é€‰æ•°æ®æç‚¼çš„ä¸»è¦å‘ç°ä¸å¯æ‰§è¡Œå»ºè®®ï¼Œä¾¿äºå½¢æˆé—­ç¯å†³ç­–ã€‚")
    st.caption("_ä»¥ä¸‹å‘ç°ä¸å»ºè®®å‡åŸºäºè§‚æµ‹æœŸæ•°æ®ï¼›å»ºè®®æŒ‰ä¼˜å…ˆçº§æ¨è¿›ï¼Œå¹¶å¯åœ¨ä¸‹æœŸæŠ¥å‘Šä¸­å¤ç›˜ã€‚_")
    col_a, col_b = st.columns(2)
    with col_a:
        st.markdown("**ä¸»è¦å‘ç°**")
        for f in narrative["findings"]:
            st.markdown(f"- {f}")
        if not narrative["findings"]:
            st.markdown("- å½“å‰æ•°æ®ä¸‹æš‚æ— é¢å¤–å‘ç°ï¼Œå¯ç»“åˆä¸Šæ–¹å›¾è¡¨åšäººå·¥è§£è¯»ã€‚")
    with col_b:
        st.markdown("**å»ºè®®ä¸‹ä¸€æ­¥**")
        for s in narrative["suggestions"]:
            st.markdown(f"- {s}")

    # ----- è¿è¥ & è´­ä¹°è¯¦æƒ… / ç”¨æˆ·åé¦ˆç­‰æ˜ç»†ï¼ˆæ¥è‡ªå¤ç›˜ PDFï¼‰-----
    summary_path = PROCESSED_DIR / "product_region_summary.csv"
    purchase_path = PROCESSED_DIR / "purchase_details.csv"
    cancel_path = PROCESSED_DIR / "cancel_details.csv"
    has_summary = summary_path.exists()
    has_purchase = purchase_path.exists()
    has_cancel = cancel_path.exists()

    # ç®¡ç†å±‚è§†å›¾ä¸‹é»˜è®¤æ”¶èµ·ï¼Œç»™è¿è¥/äº§å“çš„æ˜ç»†æŒ‰éœ€å±•å¼€
    if has_summary or has_purchase or has_cancel:
        st.markdown("---")
        with st.expander("è¿è¥ & è´­ä¹°è¯¦æƒ…ï¼ˆç»™è¿è¥/äº§å“çœ‹ï¼‰", expanded=view_mode != "ç®¡ç†å±‚æ±‡æ€»è§†å›¾"):
            st.caption("ç”¨äºæ”¯æŒæ‹‰æ–°ä¸è½¬åŒ–å¤ç›˜çš„åŒºåŸŸæ±‡æ€»ã€è´­ä¹°ä¸å–æ¶ˆæ˜ç»†ã€‚")
            if has_summary:
                st.markdown("**è¶³çƒ/ç¯®çƒ AI åˆ†æç›¸å…³æ•°æ®**")
                st.caption("æ¥æºï¼šè¶³ç¯®çƒAIåˆ†æä¸Šçº¿2å‘¨å¤ç›˜ PDFï¼ŒæŒ‰äº§å“çº¿ä¸åŒºåŸŸæ±‡æ€»ã€‚")
                try:
                    summary_df = pd.read_csv(summary_path, encoding="utf-8")
                    if not summary_df.empty and "product_line" in summary_df.columns and "region" in summary_df.columns:
                        for pl in summary_df["product_line"].unique():
                            st.markdown(f"**{pl}**")
                            sub = summary_df[summary_df["product_line"] == pl]
                            st.dataframe(sub, use_container_width=True, hide_index=True)
                except Exception as e:
                    st.caption(f"è¯»å–æ±‡æ€»è¡¨å¤±è´¥: {e}")
            if has_purchase or has_cancel:
                st.markdown("---")
                st.markdown("**è´­ä¹°/å–æ¶ˆè¯¦æƒ…ï¼ˆæ¥è‡ªå¤ç›˜ï¼‰**")
                if has_purchase:
                    try:
                        purchase_df = pd.read_csv(purchase_path, encoding="utf-8")
                        if "region" in purchase_df.columns:
                            for r in purchase_df["region"].unique():
                                st.markdown(f"**{r}ç”¨æˆ·è´­ä¹°è¯¦æƒ…**")
                                st.dataframe(purchase_df[purchase_df["region"] == r], use_container_width=True, hide_index=True)
                        else:
                            st.dataframe(purchase_df, use_container_width=True, hide_index=True)
                    except Exception as e:
                        st.caption(f"è¯»å–è´­ä¹°è¯¦æƒ…å¤±è´¥: {e}")
                if has_cancel:
                    try:
                        cancel_df = pd.read_csv(cancel_path, encoding="utf-8")
                        st.markdown("**å–æ¶ˆæ”¯ä»˜è¯¦æƒ…**")
                        st.dataframe(cancel_df, use_container_width=True, hide_index=True)
                    except Exception as e:
                        st.caption(f"è¯»å–å–æ¶ˆè¯¦æƒ…å¤±è´¥: {e}")

    feedback_path = PROCESSED_DIR / "insights_feedback.txt"
    if feedback_path.exists():
        with st.expander("ç”¨æˆ·åé¦ˆä¸åˆ†æå¤‡æ³¨ï¼ˆç»™åˆ†æ/äº§å“çœ‹ï¼‰", expanded=view_mode != "ç®¡ç†å±‚æ±‡æ€»è§†å›¾"):
            st.caption("ç”¨äºè¿˜åŸç”¨æˆ·ä¸»è§‚åé¦ˆå’Œåˆ†æå¤‡æ³¨ï¼Œæ”¯æ’‘å¯¹æ•°æ®çš„å®šæ€§åˆ¤æ–­ã€‚")
            try:
                text = feedback_path.read_text(encoding="utf-8")
                if text.strip():
                    st.markdown(text.strip())
                else:
                    st.caption("æš‚æ— å†…å®¹")
            except Exception as e:
                st.caption(f"è¯»å–å¤±è´¥: {e}")

    # ----- Data source -----
    st.divider()
    st.caption("æ•°æ®æ¥æºï¼šæ ¹ç›®å½• AI ç¯®çƒ/è¶³çƒåˆ†æçœ‹æ¿ PDFã€‚")


if __name__ == "__main__":
    main()
